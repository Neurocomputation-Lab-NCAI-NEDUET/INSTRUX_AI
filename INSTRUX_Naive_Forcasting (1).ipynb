{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HrvQysecM9my"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I9x4GjlEVTQN"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L1EqtpHwMhD2"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "fA2WAkrC6JMX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tzdoFsd3NRX5"
      },
      "source": [
        "## Utilities\n",
        "\n",
        "You will then define some utility functions to make the code more organized. First up is the plotting function you also used in the previous lab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wpo1S0UfRyoc"
      },
      "outputs": [],
      "source": [
        "def plot_series(time, series, format=\"-\", start=0, end=None):\n",
        "    \"\"\"\n",
        "    Visualizes time series data\n",
        "\n",
        "    Args:\n",
        "      time (array of int) - contains the time steps\n",
        "      series (array of int) - contains the measurements for each time step\n",
        "      format - line style when plotting the graph\n",
        "      label - tag for the line\n",
        "      start - first time step to plot\n",
        "      end - last time step to plot\n",
        "    \"\"\"\n",
        "\n",
        "    # Setup dimensions of the graph figure\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    \n",
        "    if type(series) is tuple:\n",
        "\n",
        "      for series_num in series:\n",
        "        # Plot the time series data\n",
        "        plt.plot(time[start:end], series_num[start:end], format)\n",
        "\n",
        "    else:\n",
        "      # Plot the time series data\n",
        "      plt.plot(time[start:end], series[start:end], format)\n",
        "\n",
        "    # Label the x-axis\n",
        "    plt.xlabel(\"Time\")\n",
        "\n",
        "    # Label the y-axis\n",
        "    plt.ylabel(\"Value\")\n",
        "\n",
        "    # Overlay a grid on the graph\n",
        "    plt.grid(True)\n",
        "\n",
        "    # Draw the graph on screen\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DdpA3Cvn6H4x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nk1l6rCEwFK1"
      },
      "source": [
        "You will also place the functions to generate your synthetic data here. For this lab, you will just need trend, seasonality, and noise. Feel free to add others later in case you want a more challenging task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gos26mZwwF66"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RsI6IxHvNXmF"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gqWabzlJ63nL"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "data=pd.read_csv(\"/content/drive/MyDrive/Instrux_rainbow/Instrux-Daily-energy.csv\")\n",
        "time=data['Day']\n",
        "series=data['energyValue']"
      ],
      "metadata": {
        "id": "5WNo9PDB6Yzw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UfdyqJJ1VZVu"
      },
      "source": [
        "## Split the Dataset\n",
        "\n",
        "Next up, you will split the data above into training and validation sets. You will take the first 1,000 points for training while the rest is for validation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_w0eKap5uFNP"
      },
      "outputs": [],
      "source": [
        "# Define the split time\n",
        "split_time = 38\n",
        "\n",
        "# Get the train set \n",
        "time_train = time[:split_time]\n",
        "x_train = series[:split_time]\n",
        "\n",
        "# Get the validation set\n",
        "time_valid = time[split_time:]\n",
        "x_valid = series[split_time:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dLs01JDDzDun"
      },
      "source": [
        "You can inspect these sets visually by using the same utility function for plotting. Notice that in general, the validation set has higher values (i.e. y-axis) than those in the training set. Your model should be able to predict those values just by learning from the trend and seasonality of the training set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qH84AOTOSnxr"
      },
      "outputs": [],
      "source": [
        "# Plot the train set\n",
        "plot_series(time_train, x_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YS3D4YpqSl3n"
      },
      "outputs": [],
      "source": [
        "# Plot the validation set\n",
        "plot_series(time_valid, x_valid)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bjD8ncEZbjEW"
      },
      "source": [
        "# Naive Forecast\n",
        "\n",
        "As a baseline, you can do a naive forecast where you assume that the next value will be the same as the previous time step. You can slice the original series like below and print some values as a sanity check. The next time step value should be identical to the ground truth at the previous time step."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pj_-uCeYxcAb"
      },
      "outputs": [],
      "source": [
        "# Generate the naive forecast\n",
        "naive_forecast = series[split_time - 1:-1]\n",
        "\n",
        "# Define time step\n",
        "#time_step = 1\n",
        "\n",
        "# Print values\n",
        "#print(f'ground truth at time step {time_step}: {x_valid[time_step]}')\n",
        "#print(f'prediction at time step {time_step + 1}: {naive_forecast[time_step + 1]}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YtGUyT3B2PT6"
      },
      "source": [
        "You can see this visually with the `plot_series()` function you defined earlier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vk51IA7z1Ym9"
      },
      "outputs": [],
      "source": [
        "# Plot the results\n",
        "plot_series(time_valid, (x_valid, naive_forecast))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jn-IT9pWZ1xQ"
      },
      "source": [
        "You can zoom in at the start of the validation period to see that the naive forecast lags 1 step behind the time series."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D0MKg7FNug9V"
      },
      "outputs": [],
      "source": [
        "# Zooming in\n",
        "plot_series(time_valid, (x_valid, naive_forecast), start=0, end=150)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uh_7244Gsxfx"
      },
      "source": [
        "### Computing Metrics\n",
        "\n",
        "Now you will compute the [mean squared error](https://www.tensorflow.org/api_docs/python/tf/keras/metrics/mean_squared_error) and the [mean absolute error](https://www.tensorflow.org/api_docs/python/tf/keras/metrics/mean_absolute_error) between the forecasts and the predictions in the validation period. These are available via the [`tf.keras.metrics`](https://www.tensorflow.org/api_docs/python/tf/keras/metrics/) API. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "byNnC7IbsnMZ"
      },
      "outputs": [],
      "source": [
        "print(tf.keras.metrics.mean_squared_error(x_valid, naive_forecast).numpy())\n",
        "print(tf.keras.metrics.mean_absolute_error(x_valid, naive_forecast).numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "goTJyTdw3PP5"
      },
      "source": [
        "The values above will be your baseline and you will see if you can use other methods to do better than naive forecasting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGPBC9QttI1u"
      },
      "source": [
        "## Moving Average\n",
        "\n",
        "One technique you can use is to do a moving average. This sums up a series of time steps and the average will be the prediction for the next time step. For example, the average of the measurements at time steps 1 to 10 will be the forecast for time step 11, then the average for time steps 2 to 11 will be the forecast for time step 12, and so on.\n",
        "\n",
        "The function below does the moving average for the entire `series`. It takes a `window_size` argument to indicate the number of time steps to consider when computing the mean."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YGz5UsUdf2tV"
      },
      "outputs": [],
      "source": [
        "def moving_average_forecast(series, window_size):\n",
        "    \"\"\"Generates a moving average forecast\n",
        "\n",
        "    Args:\n",
        "      series (array of float) - contains the values of the time series\n",
        "      window_size (int) - the number of time steps to compute the average for\n",
        "\n",
        "    Returns:\n",
        "      forecast (array of float) - the moving average forecast\n",
        "    \"\"\"\n",
        "\n",
        "    # Initialize a list\n",
        "    forecast = []\n",
        "    \n",
        "    # Compute the moving average based on the window size\n",
        "    for time in range(len(series) - window_size):\n",
        "      forecast.append(series[time:time + window_size].mean())\n",
        "    \n",
        "    # Convert to a numpy array\n",
        "    forecast = np.array(forecast)\n",
        "\n",
        "    return forecast"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pjiVlKXA5UXK"
      },
      "source": [
        "You will use this function to generate the forecast with a window size of `30`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HHFhGXQji7_r"
      },
      "outputs": [],
      "source": [
        "# Generate the moving average forecast\n",
        "moving_avg = moving_average_forecast(series, 30)[split_time - 30:]\n",
        "\n",
        "# Plot the results\n",
        "plot_series(time_valid, (x_valid, moving_avg))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wG7pTAd7z0e8"
      },
      "outputs": [],
      "source": [
        "# Compute the metrics\n",
        "print(tf.keras.metrics.mean_squared_error(x_valid, moving_avg).numpy())\n",
        "print(tf.keras.metrics.mean_absolute_error(x_valid, moving_avg).numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JMYPnJqwz8nS"
      },
      "source": [
        "That's worse than naive forecast! The moving average does not anticipate trend or seasonality. In particular, those huge spikes in the original series causes big deviations as shown in the plot above. You will try to remove these characteristics of the dataset with time differencing and see if you get better results."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}